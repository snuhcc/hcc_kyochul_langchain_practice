


from openai import OpenAI
import json
import argparse
import tqdm
import time
import os
import dotenv
from pathlib import Path, PosixPath
import time
import re
import dotenv
dotenv.load_dotenv()
import gen_dataset_json
import math
import utils





save_fp = utils.gen_dataset() # Generate section_data.json from the datasets in pre_dataset directory
print(save_fp)





fp = utils.create_batch_jsonl(save_fp) # Create batch jsonl file for all dataset in post_dataset directory
print(fp)





pre_path = Path('data/post_dataset')
all = set()
for fp in pre_path.glob('*.jsonl'):
    if 'LLAMA' in fp.name:
        all.add(fp)
t = all.copy()
for fp in Path('batch_result').glob('*.jsonl'):
    for temp in t:
        if fp.name in str(temp):
            all.remove(temp)

print(len(all))


res_dict = {}
cur_path = Path('data/post_dataset')

for fp in sorted(all):
    if 'LLAMA' in fp.name:
        score_binary_file_path, batch_result = utils.run_batch(fp)
        res_dict[score_binary_file_path] = batch_result


res_dict = {}
cur_path = Path('data/post_dataset')

for fp in cur_path.glob('*.jsonl'):
    if 'LLAMA' in fp.name:
        score_binary_file_path, batch_result = utils.run_batch(fp)
        res_dict[score_binary_file_path] = batch_result





cur_path = Path('batch_result')

for file in cur_path.glob('*.jsonl'):
    if 'QWEN2' in file.name:
        samples = utils.get_batch_score(file)
        print(len(samples))



fp = Path('batch_result/QWEN2_5_72B_BOOK.jsonl')


from pathlib import Path, PosixPath

def get_batch_score(fp: PosixPath):
    samples = {}
    with open(fp, 'r') as file:
        for line in file:
            line = json.loads(line.strip())
            sample = line['custom_id'][:line['custom_id'].find('_<Section')]
            criteria = line['custom_id'][line['custom_id'].rfind('_')+1:]

            if sample not in samples:
                samples[sample] = {'weighted_con': 0,  'weighted_rel': 0, 'weighted_faith': 0, 'top_con': 0, 'top_rel': 0, 'top_faith': 0, 'count': 0}
            top_logprobs = line['response']['body']['choices'][0]['logprobs']['content'][0]['top_logprobs']
            samples[sample][f'top_{criteria}'] += float(line['response']['body']['choices'][0]['logprobs']['content'][0]['token'])
            
            for tokens in top_logprobs:
                try:
                    score = int(tokens['token'])
                except ValueError:
                    continue

                if int(tokens['token']) < 1 or int(tokens['token']) > 5:
                    continue

                try:
                    logprob = tokens['logprob']
                except KeyError:
                    logprob = float('-inf')
                prob = np.exp(logprob)
                samples[sample][f'weighted_{criteria}'] += score * prob

            samples[sample]['count'] += 1
            
    for sample in samples:
        samples[sample]['count'] /= 3
        
        for score in samples[sample]:
            samples[sample][score] /= samples[sample]['count']
            
        samples[sample]['weighted'] = sum(samples[sample][feature] for feature in samples[sample] if 'weighted' in feature) / 3
        samples[sample]['top'] = sum(samples[sample][feature] for feature in samples[sample] if 'top' in feature) / 3

    save_path = Path('score') / f'{fp.stem}.json'
    with open(Path('score') / f'{fp.stem}.json', 'w') as file:
        json.dump(samples, file, indent=4)

    print(f"Output has been saved to {save_path}")
    
    return samples


temp = get_batch_score(fp)


temp = Path('data/post_dataset')
count = 0
for sample in temp.glob('*.jsonl'):
    if 'QWEN' not in sample.name and 'LLAMA' not in sample.name:
        print(sample.name)
        count += 1
print(count)



